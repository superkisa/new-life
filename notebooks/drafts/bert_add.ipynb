{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from mujoco import viewer\n",
    "from stable_baselines3 import SAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.normal import Normal\n",
    "from transformers import DistilBertConfig, DistilBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from numpy.typing import NDArray\n",
    "from torch import nn\n",
    "from transformers import DistilBertConfig, DistilBertModel\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                #  observation_space,\n",
    "                #  features_dim,\n",
    "                #  action_space,\n",
    "                #  lr_schedule,\n",
    "                 num_struct_elements: int,\n",
    "                 attention_mask: NDArray[np.int_],\n",
    "                 components_mask: NDArray[np.int_]):\n",
    "        self.bert_config = DistilBertConfig(\n",
    "            vocab_size=10000,\n",
    "            hidden_size=1,\n",
    "            num_hidden_layers=2,\n",
    "            num_attention_heads=1,\n",
    "            intermediate_size=100,\n",
    "            hidden_act=\"gelu\",\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=50,\n",
    "            type_vocab_size=2,\n",
    "            initializer_range=0.02,\n",
    "            layer_norm_eps=1e-12,\n",
    "            pad_token_id=0,\n",
    "            position_embedding_type=\"absolute\",\n",
    "            use_cache=True,\n",
    "            classifier_dropout=None,\n",
    "        )\n",
    "        super().__init__()\n",
    "        self.num_struct_elements = num_struct_elements\n",
    "        self.attention_mask = attention_mask\n",
    "        self.components_mask = components_mask\n",
    "        self.distilbert_1 = DistilBertModel(self.bert_config)\n",
    "        self.distilbert_2 = DistilBertModel(self.bert_config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        inputs_embeds: NDArray[np.float_],\n",
    "        # num_struct_elements: int = 9,\n",
    "        # attention_mask: NDArray[np.int_] = None,\n",
    "        # components_mask: NDArray[np.int_] = None,\n",
    "    ):\n",
    "        attention_mask = torch.from_numpy(self.attention_mask).to(torch.int64)\n",
    "        components_mask = torch.from_numpy(self.components_mask).to(torch.int64)\n",
    "\n",
    "        embeds = np.array([inputs_embeds for _ in range(self.num_struct_elements)])\n",
    "\n",
    "        embeds = torch.from_numpy(embeds).to(torch.float32)\n",
    "\n",
    "        embeds = embeds.view(embeds.size()[0], embeds.size()[1], 1)\n",
    "        outputs_1 = self.distilbert_1(\n",
    "            # input_ids=torch.ones(input_ids.size()),\n",
    "            inputs_embeds=embeds,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        last_hidden_state_1 = outputs_1[\"last_hidden_state\"]\n",
    "\n",
    "        input_2 = torch.sum(last_hidden_state_1, dim=2)\n",
    "        input_2.mul_(components_mask)  # summing through columns\n",
    "        input_2 = torch.sum(input_2, dim=0)\n",
    "        ones_vector = torch.ones(self.num_struct_elements, 1)\n",
    "        input_2 = ones_vector @ input_2.view(1, input_2.size()[0])\n",
    "\n",
    "        input_2 = input_2.view(input_2.size()[0], input_2.size()[1], 1)\n",
    "\n",
    "        outputs_2 = self.distilbert_2(\n",
    "            # input_ids=torch.ones(input_2.size()),\n",
    "            inputs_embeds=input_2,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        last_hidden_state_2 = outputs_2[\"last_hidden_state\"]\n",
    "\n",
    "        input_2 = torch.sum(last_hidden_state_2, axis=2)\n",
    "        input_2.mul_(components_mask)\n",
    "        # summing through columns\n",
    "        input_2 = torch.sum(input_2, axis=0)\n",
    "        return input_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QHead(nn.Module):\n",
    "    def __init__(self, size_input, size_action):\n",
    "        super(QHead, self).__init__()\n",
    "        self.size_input = size_input\n",
    "        self.size_action = size_action\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(self.size_input, self.size_action),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(self.size_action, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layer(input)\n",
    "\n",
    "\n",
    "class PiHead(nn.Module):\n",
    "    def __init__(self, size_input, size_action):\n",
    "        super(PiHead, self).__init__()\n",
    "        self.size_input = size_input\n",
    "        self.size_action = size_action\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(self.size_input, self.size_action),\n",
    "            nn.LeakyReLU(0.01),\n",
    "        )\n",
    "\n",
    "        self.last_lin = nn.Linear(1, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output_1 = self.layer(input)\n",
    "        # ones_vector = torch.ones(self.size_action, 1)\n",
    "        # output_1 = ones_vector @ output_1.view(1, self.size_action)\n",
    "        return self.last_lin(output_1.view(self.size_action, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CustomModel(num_struct_elements=2,\n",
    "    attention_mask=np.array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]),\n",
    "    components_mask=np.array([[1, 1, 1, 0, 0], [0, 0, 0, 1, 1]]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = v(\n",
    "    inputs_embeds=np.array([0.9086, 0, 0.4586, 0.60, 0.1300])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3234,  0.1756],\n",
       "        [-0.3457,  0.1512],\n",
       "        [-0.3450,  0.1520]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = PiHead(5, 3)\n",
    "n = b(out)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mujoco import viewer\n",
    "from stable_baselines3 import SAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant_xml = Path(\"assets/ant.xml\").resolve()\n",
    "# env = gym.make('Ant-v4', ctrl_cost_weight=0.1, use_contact_forces=True, render_mode=\"human\")\n",
    "env = gym.make(\"Ant-v4\", xml_file=str(ant_xml), render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.34447477e-01,  9.92621542e-01,  6.75538196e-02, -9.93757526e-02,\n",
       "       -1.62300769e-02,  1.15063916e-02,  8.59142021e-02, -1.91279499e-02,\n",
       "        4.14099744e-02, -9.77306455e-02,  8.05495065e-02,  4.75159271e-03,\n",
       "        8.14847604e-02, -4.77236883e-02, -6.88342638e-02, -6.63389699e-02,\n",
       "        1.86202157e-03, -3.65168499e-02, -6.55175676e-02, -2.71269819e-02,\n",
       "       -6.80848270e-02, -2.15879968e-01, -4.89127362e-02,  6.45033340e-02,\n",
       "        8.09131860e-02, -4.23027574e-04,  1.49368267e-01])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomModel,\n",
    "    features_extractor_kwargs=dict(num_struct_elements=1,\n",
    "    attention_mask=np.array([1]*27),\n",
    "    components_mask=np.array([1]*27),),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomModel' object has no attribute 'features_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSAC\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:157\u001b[0m, in \u001b[0;36mSAC.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_coef_optimizer: Optional[th\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:160\u001b[0m, in \u001b[0;36mSAC._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# Running mean and running var\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:199\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m         replay_buffer_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:278\u001b[0m, in \u001b[0;36mSACPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, use_sde, log_std_init, use_expln, clip_mean, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs, n_critics, share_features_extractor)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    269\u001b[0m     {\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_critics\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_critics,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m     }\n\u001b[0;32m    274\u001b[0m )\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor \u001b[38;5;241m=\u001b[39m share_features_extractor\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:281\u001b[0m, in \u001b[0;36mSACPolicy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr_schedule: Schedule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_class(\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[0;32m    284\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr_schedule(\u001b[38;5;241m1\u001b[39m),  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs,\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:342\u001b[0m, in \u001b[0;36mSACPolicy.make_actor\u001b[1;34m(self, features_extractor)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, features_extractor: Optional[BaseFeaturesExtractor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Actor:\n\u001b[1;32m--> 342\u001b[0m     actor_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Actor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mactor_kwargs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:115\u001b[0m, in \u001b[0;36mBaseModel._update_features_extractor\u001b[1;34m(self, net_kwargs, features_extractor)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# The features extractor is not shared, create a new one\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     features_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_features_extractor()\n\u001b[1;32m--> 115\u001b[0m net_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(features_extractor\u001b[38;5;241m=\u001b[39mfeatures_extractor, features_dim\u001b[38;5;241m=\u001b[39m\u001b[43mfeatures_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_dim\u001b[49m))\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net_kwargs\n",
      "File \u001b[1;32mc:\\Users\\COCUTERSASHA\\.micromamba\\envs\\ml311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomModel' object has no attribute 'features_dim'"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = 1\n",
    "d_k = 1\n",
    "\n",
    "# Assume these are given\n",
    "X = np.random.rand(4, d)  # Replace with actual embeddings\n",
    "W_q = np.random.rand(d, d_k)  # Replace with actual W_q\n",
    "W_k = np.random.rand(d, d_k)  # Replace with actual W_k\n",
    "G = np.array([[1, 1, 0, 0],\n",
    "              [1, 1, 1, 0],\n",
    "              [0, 1, 1, 1],\n",
    "              [0, 0, 1, 1]])\n",
    "\n",
    "# Compute Q and K\n",
    "Q = np.dot(X, W_q)\n",
    "K = np.dot(X, W_k)\n",
    "\n",
    "# Compute Scores\n",
    "Scores = np.dot(Q, K.T)\n",
    "\n",
    "# Mask Scores\n",
    "Masked_Scores = Scores * G\n",
    "\n",
    "# Apply Softmax\n",
    "A = np.exp(Masked_Scores) / np.exp(Masked_Scores).sum(axis=1, keepdims=True)\n",
    "\n",
    "# Compute New Node Embeddings\n",
    "Z = np.dot(A, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[0.08576015]\n",
      " [0.50997662]\n",
      " [0.34750299]\n",
      " [0.03052557]]\n",
      "W_q [[0.21283992]]\n",
      "W_k [[0.93008227]]\n",
      "Q [[0.01825318]\n",
      " [0.10854339]\n",
      " [0.07396251]\n",
      " [0.00649706]]\n",
      "K [[0.079764  ]\n",
      " [0.47432021]\n",
      " [0.32320637]\n",
      " [0.02839129]]\n",
      "Scores [[0.00145595 0.00865785 0.00589955 0.00051823]\n",
      " [0.00865785 0.05148432 0.03508191 0.00308169]\n",
      " [0.00589955 0.03508191 0.02390515 0.00209989]\n",
      " [0.00051823 0.00308169 0.00209989 0.00018446]]\n",
      "Masked_Scores [[0.00145595 0.00865785 0.         0.        ]\n",
      " [0.00865785 0.05148432 0.03508191 0.        ]\n",
      " [0.         0.03508191 0.02390515 0.00209989]\n",
      " [0.         0.         0.00209989 0.00018446]]\n",
      "A [[0.24973041 0.25153544 0.24936708 0.24936708]\n",
      " [0.24618945 0.2569619  0.25278148 0.24406717]\n",
      " [0.24618416 0.25497405 0.25214013 0.24670166]\n",
      " [0.24985717 0.24985717 0.25038239 0.24990326]]\n",
      "Z [[0.24396199]\n",
      " [0.24745041]\n",
      " [0.24629375]\n",
      " [0.24348617]]\n"
     ]
    }
   ],
   "source": [
    "print('X', X)\n",
    "print('W_q', W_q)\n",
    "print('W_k', W_k)\n",
    "print('Q', Q)\n",
    "print('K', K)\n",
    "print('Scores', Scores)\n",
    "print('Masked_Scores', Masked_Scores)\n",
    "print('A', A)\n",
    "print('Z', Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
